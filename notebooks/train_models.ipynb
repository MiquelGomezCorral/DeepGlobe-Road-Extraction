{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# PATH MANAGEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "if not os.getcwd().endswith(\"app\"):\n",
    "    os.chdir(\"../app\")\n",
    "    print(os.getcwd())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# TRAIN SEGMENTATION MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import Configuration\n",
    "\n",
    "CONFIG = Configuration(\n",
    "    max_samples=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.data import AUG_PIPELINES\n",
    "\n",
    "from src.models import RoadSegmentationDataset\n",
    "\n",
    "train_dataset = RoadSegmentationDataset(CONFIG.train_folder, CONFIG, AUG_PIPELINES[\"single\"])\n",
    "valid_dataset = RoadSegmentationDataset(CONFIG.val_folder, CONFIG)\n",
    "test_dataset  = RoadSegmentationDataset(CONFIG.test_folder, CONFIG)\n",
    "\n",
    "n_cpu = os.cpu_count()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=CONFIG.batch_size, shuffle=True, num_workers=n_cpu)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=CONFIG.batch_size, shuffle=False, num_workers=n_cpu)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=CONFIG.batch_size, shuffle=False, num_workers=n_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.plot_sample(i)\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import RoadSegmentationModel\n",
    "from src.utils import get_device\n",
    "\n",
    "model = RoadSegmentationModel(CONFIG)\n",
    "model = model.to(get_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=CONFIG.epochs, log_every_n_steps=1)\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=valid_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metrics = trainer.validate(model, dataloaders=valid_dataloader, verbose=False)\n",
    "print(valid_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = trainer.validate(model, dataloaders=test_dataloader, verbose=False)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (C, H, W), (1, H, W)\n",
    "test_dataset[0][0].shape, test_dataset[0][1].shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from src.utils import get_device, to_device\n",
    "from tqdm import tqdm\n",
    "# Collect up to 20 samples from the dataloader\n",
    "max_samples = 20\n",
    "all_images, all_masks, all_preds = [], [], []\n",
    "\n",
    "for batch in tqdm(test_dataloader, desc=\"Processing batches\"):\n",
    "    images, masks = batch\n",
    "    images = to_device(images)\n",
    "    masks  = to_device(masks)\n",
    "\n",
    "    model = model.to(get_device())\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        logits = model(images)\n",
    "        probs  = torch.sigmoid(logits)\n",
    "        preds  = (probs > 0.5).float()\n",
    "\n",
    "    all_images.append(images.cpu())\n",
    "    all_masks.append(masks.cpu())\n",
    "    all_preds.append(preds.cpu())\n",
    "\n",
    "    if sum(img.shape[0] for img in all_images) >= max_samples:\n",
    "        break\n",
    "\n",
    "# Flatten the batches and limit to max_samples\n",
    "all_images = torch.cat(all_images)[:max_samples]\n",
    "all_masks  = torch.cat(all_masks)[:max_samples]\n",
    "all_preds  = torch.cat(all_preds)[:max_samples]\n",
    "\n",
    "# Plot all in a grid: 3 rows (Image, GT, Pred), N columns = number of samples\n",
    "n_samples = all_images.shape[0]\n",
    "fig, axes = plt.subplots(3, n_samples, figsize=(3 * n_samples, 9))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    img_np  = all_images[i].permute(1, 2, 0).numpy()\n",
    "    mask_np = all_masks[i].squeeze(0).numpy()\n",
    "    pred_np = all_preds[i].squeeze(0).numpy()\n",
    "\n",
    "    axes[0, i].imshow(img_np)\n",
    "    axes[0, i].axis(\"off\")\n",
    "    axes[0, i].set_title(\"Image\")\n",
    "\n",
    "    axes[1, i].imshow(mask_np, cmap=\"gray\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "    axes[1, i].set_title(\"Ground Truth\")\n",
    "\n",
    "    axes[2, i].imshow(pred_np, cmap=\"gray\")\n",
    "    axes[2, i].axis(\"off\")\n",
    "    axes[2, i].set_title(\"Prediction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
